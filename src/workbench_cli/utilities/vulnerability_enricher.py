"""
Vulnerability data enrichment utilities.

This module provides functionality to enhance vulnerability data with external sources
including NVD, EPSS scores, CISA KEV data, and alternative vulnerability databases.
"""

import json
import requests
import time
import logging
import os
import threading
from typing import Dict, List, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)

# External API configurations
EPSS_API_URL = "https://api.first.org/data/v1/epss"
NVD_API_URL = "https://services.nvd.nist.gov/rest/json/cves/2.0"
CISA_KEV_URL = "https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json"
EXPLOITDB_SEARCH_URL = "https://www.exploit-db.com/api/v1/search/"

# Alternative vulnerability data sources
VULNERS_API_URL = "https://vulners.com/api/v3/search/id"
VULNCHECK_NVD_URL = "https://api.vulncheck.com/v3/index/nvd2-cves"
OSV_API_URL = "https://api.osv.dev/v1/query"

# Rate limiting settings
NVD_RATE_LIMIT_NO_KEY = 5  # requests per 30 seconds without API key
NVD_RATE_LIMIT_WITH_KEY = 50  # requests per 30 seconds with API key
EPSS_RATE_LIMIT = 100  # requests per minute
REQUEST_TIMEOUT = 30  # seconds


def enrich_vulnerabilities(cve_list: List[str], 
                          include_descriptions: bool = True,
                          include_epss_scores: bool = True,
                          include_exploit_info: bool = True,
                          api_timeout: int = 30) -> Dict[str, Dict[str, Any]]:
    """
    Enrich vulnerability data with external sources.
    
    Args:
        cve_list: List of CVE IDs to enrich
        include_descriptions: Whether to fetch CVE descriptions from NVD
        include_epss_scores: Whether to fetch EPSS scores from FIRST
        include_exploit_info: Whether to fetch known exploit information
        api_timeout: Timeout for external API calls in seconds
        
    Returns:
        Dict mapping CVE IDs to their external data
    """
    if not cve_list:
        return {}
    
    return _fetch_external_vulnerability_data(
        cve_list, 
        include_descriptions, 
        include_epss_scores, 
        include_exploit_info,
        api_timeout
    )


def _fetch_external_vulnerability_data(cve_list: List[str], 
                                     include_descriptions: bool = True,
                                     include_epss: bool = True, 
                                     include_exploits: bool = True,
                                     timeout: int = 30) -> Dict[str, Dict[str, Any]]:
    """
    Fetch external vulnerability data from multiple sources.
    
    Returns:
        Dict mapping CVE IDs to their external data
    """
    external_data = {}
    
    # Initialize data structure
    for cve in cve_list:
        external_data[cve] = {
            "epss_score": None,
            "epss_percentile": None,
            "cisa_kev": False,
            "exploitdb_count": 0,
            "nvd_description": None,
            "nvd_cwe": None,
            "nvd_references": [],
            "full_cvss_vector": None,
            "attack_vector_detail": None
        }
    
    # Fetch data from different sources
    try:
        if include_epss:
            epss_data = _fetch_epss_scores(cve_list, timeout)
            for cve, data in epss_data.items():
                if cve in external_data:
                    external_data[cve].update(data)
    except Exception as e:
        logger.warning(f"Failed to fetch EPSS data: {e}")
    
    try:
        if include_exploits:
            kev_data = _fetch_cisa_kev_data(cve_list, timeout)
            for cve in kev_data:
                if cve in external_data:
                    external_data[cve]["cisa_kev"] = True
    except Exception as e:
        logger.warning(f"Failed to fetch CISA KEV data: {e}")
    
    try:
        if include_descriptions:
            nvd_data = _fetch_nvd_data(cve_list, timeout)
            for cve, data in nvd_data.items():
                if cve in external_data:
                    external_data[cve].update(data)
    except Exception as e:
        logger.warning(f"Failed to fetch NVD data: {e}")
    
    return external_data


def _fetch_epss_scores(cve_list: List[str], timeout: int = 30) -> Dict[str, Dict[str, Any]]:
    """Fetch EPSS scores from FIRST API."""
    epss_data = {}
    
    # EPSS API supports batch queries
    batch_size = 100  # API limit
    for i in range(0, len(cve_list), batch_size):
        batch = cve_list[i:i + batch_size]
        cve_param = ",".join(batch)
        
        try:
            response = requests.get(
                f"{EPSS_API_URL}?cve={cve_param}",
                timeout=timeout,
                headers={"User-Agent": "FossID-Workbench-CLI/1.0"}
            )
            response.raise_for_status()
            
            data = response.json()
            if data.get("status") == "OK" and "data" in data:
                for item in data["data"]:
                    cve = item.get("cve")
                    if cve:
                        epss_data[cve] = {
                            "epss_score": float(item.get("epss", 0)),
                            "epss_percentile": float(item.get("percentile", 0))
                        }
            
            # Rate limiting
            time.sleep(1)
            
        except Exception as e:
            logger.warning(f"Failed to fetch EPSS data for batch {i//batch_size + 1}: {e}")
    
    return epss_data


def _fetch_cisa_kev_data(cve_list: List[str], timeout: int = 30) -> List[str]:
    """Fetch CISA Known Exploited Vulnerabilities data."""
    try:
        response = requests.get(
            CISA_KEV_URL,
            timeout=timeout,
            headers={"User-Agent": "FossID-Workbench-CLI/1.0"}
        )
        response.raise_for_status()
        
        kev_data = response.json()
        known_exploited = set()
        
        if "vulnerabilities" in kev_data:
            for vuln in kev_data["vulnerabilities"]:
                cve = vuln.get("cveID")
                if cve and cve in cve_list:
                    known_exploited.add(cve)
        
        return list(known_exploited)
        
    except Exception as e:
        logger.warning(f"Failed to fetch CISA KEV data: {e}")
        return []


def _fetch_nvd_data(cve_list: List[str], timeout: int = 30) -> Dict[str, Dict[str, Any]]:
    """
    Fetch detailed CVE information from NVD API 2.0 with enhanced performance and reliability.
    
    Improvements:
    - Concurrent processing with rate limiting
    - Exponential backoff retry logic
    - In-memory caching for duplicate requests
    - API key support for higher rate limits
    - Progress tracking for large CVE lists
    - Alternative data source fallback
    """
    return _fetch_nvd_data_enhanced(cve_list, timeout)


def _fetch_nvd_data_enhanced(cve_list: List[str], timeout: int = 30) -> Dict[str, Dict[str, Any]]:
    """Enhanced NVD data fetching with concurrent processing and intelligent rate limiting."""
    nvd_data = {}
    
    if not cve_list:
        return nvd_data
    
    # Check for API key in environment variables
    api_key = os.environ.get('NVD_API_KEY')
    max_workers = 5 if api_key else 2  # Higher concurrency with API key
    rate_limit_delay = 0.6 if api_key else 6  # 50 requests per 30s with key, 5 per 30s without
    
    # Initialize rate limiter
    rate_limiter = RateLimiter(max_workers, rate_limit_delay)
    
    # Initialize cache
    cache = {}
    
    logger.info(f"Fetching NVD data for {len(cve_list)} CVEs using {'API key' if api_key else 'public rate limits'}")
    
    # Filter out already cached CVEs
    cves_to_fetch = [cve for cve in cve_list if cve not in cache]
    
    if not cves_to_fetch:
        logger.info("All CVEs found in cache")
        return {cve: cache[cve] for cve in cve_list}
    
    # Process CVEs concurrently
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all tasks
        future_to_cve = {
            executor.submit(_fetch_single_cve_nvd, cve, api_key, rate_limiter, timeout): cve
            for cve in cves_to_fetch
        }
        
        # Collect results with progress tracking
        completed = 0
        for future in as_completed(future_to_cve):
            cve = future_to_cve[future]
            completed += 1
            
            try:
                result = future.result()
                if result:
                    nvd_data[cve] = result
                    cache[cve] = result  # Cache successful results
                
                if completed % 10 == 0 or completed == len(cves_to_fetch):
                    logger.info(f"Processed {completed}/{len(cves_to_fetch)} CVEs")
                    
            except Exception as e:
                logger.warning(f"Failed to fetch NVD data for {cve}: {e}")
                # Try alternative data source as fallback
                try:
                    alternative_data = _fetch_alternative_vulnerability_data(cve, timeout)
                    if alternative_data:
                        nvd_data[cve] = alternative_data
                        logger.info(f"Used alternative data source for {cve}")
                except Exception as alt_e:
                    logger.warning(f"Alternative data source also failed for {cve}: {alt_e}")
    
    return nvd_data


def _fetch_single_cve_nvd(cve: str, api_key: Optional[str], rate_limiter: 'RateLimiter', 
                         timeout: int) -> Optional[Dict[str, Any]]:
    """Fetch a single CVE from NVD with retry logic and rate limiting."""
    headers = {"User-Agent": "FossID-Workbench-CLI/1.0"}
    if api_key:
        headers["apiKey"] = api_key
    
    max_retries = 3
    base_delay = 1.0
    
    for attempt in range(max_retries):
        try:
            # Wait for rate limiter
            rate_limiter.wait()
            
            response = requests.get(
                f"{NVD_API_URL}?cveId={cve}",
                timeout=timeout,
                headers=headers
            )
            
            # Handle rate limiting
            if response.status_code == 429:
                retry_after = int(response.headers.get('Retry-After', 60))
                logger.warning(f"Rate limited for {cve}, waiting {retry_after}s")
                time.sleep(retry_after)
                continue
            
            response.raise_for_status()
            
            data = response.json()
            if "vulnerabilities" in data and data["vulnerabilities"]:
                return _parse_nvd_vulnerability(data["vulnerabilities"][0]["cve"])
            
            return None
            
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                delay = base_delay * (2 ** attempt)  # Exponential backoff
                logger.warning(f"Request failed for {cve}, retrying in {delay}s: {e}")
                time.sleep(delay)
            else:
                logger.error(f"Failed to fetch {cve} after {max_retries} attempts: {e}")
                raise
    
    return None


def _parse_nvd_vulnerability(vuln_data: Dict[str, Any]) -> Dict[str, Any]:
    """Parse NVD vulnerability data into standardized format."""
    # Extract description
    description = "No description available"
    if "descriptions" in vuln_data:
        for desc in vuln_data["descriptions"]:
            if desc.get("lang") == "en":
                description = desc.get("value", description)
                break
    
    # Extract CWE information
    cwe_ids = []
    if "weaknesses" in vuln_data:
        for weakness in vuln_data["weaknesses"]:
            if weakness.get("type") == "Primary":
                for desc in weakness.get("description", []):
                    if desc.get("lang") == "en":
                        cwe_ids.append(desc.get("value", ""))
    
    # Extract references
    references = []
    if "references" in vuln_data:
        for ref in vuln_data["references"][:10]:  # Increased to 10 references
            references.append({
                "url": ref.get("url", ""),
                "source": ref.get("source", ""),
                "tags": ref.get("tags", [])
            })
    
    # Extract full CVSS vector
    full_cvss_vector = None
    cvss_score = None
    if "metrics" in vuln_data:
        for metric_type in ["cvssMetricV31", "cvssMetricV30", "cvssMetricV2"]:
            if metric_type in vuln_data["metrics"]:
                metrics = vuln_data["metrics"][metric_type]
                if metrics and len(metrics) > 0:
                    cvss_data = metrics[0].get("cvssData", {})
                    full_cvss_vector = cvss_data.get("vectorString")
                    cvss_score = cvss_data.get("baseScore")
                    break
    
    return {
        "nvd_description": description,
        "nvd_cwe": cwe_ids,
        "nvd_references": references,
        "full_cvss_vector": full_cvss_vector,
        "cvss_score": cvss_score
    }


def _fetch_alternative_vulnerability_data(cve: str, timeout: int = 30) -> Optional[Dict[str, Any]]:
    """
    Fetch vulnerability data from alternative sources when NVD fails.
    Currently supports Vulners API as primary alternative.
    """
    # Try Vulners API first
    try:
        vulners_data = _fetch_vulners_data(cve, timeout)
        if vulners_data:
            return vulners_data
    except Exception as e:
        logger.debug(f"Vulners API failed for {cve}: {e}")
    
    # Could add more alternative sources here
    return None


def _fetch_vulners_data(cve: str, timeout: int = 30) -> Optional[Dict[str, Any]]:
    """Fetch vulnerability data from Vulners API."""
    try:
        # Vulners search API endpoint
        vulners_url = "https://vulners.com/api/v3/search/id"
        
        payload = {
            "id": cve,
            "fields": ["*"]
        }
        
        response = requests.post(
            vulners_url,
            json=payload,
            timeout=timeout,
            headers={"User-Agent": "FossID-Workbench-CLI/1.0"}
        )
        
        if response.status_code == 200:
            data = response.json()
            if data.get("result") == "OK" and data.get("data"):
                vuln_data = data["data"]["documents"][0]
                
                return {
                    "nvd_description": vuln_data.get("description", "No description available"),
                    "nvd_cwe": vuln_data.get("cwe", []),
                    "nvd_references": [{"url": ref, "source": "vulners"} for ref in vuln_data.get("references", [])[:10]],
                    "full_cvss_vector": vuln_data.get("cvss", {}).get("vector"),
                    "cvss_score": vuln_data.get("cvss", {}).get("score"),
                    "source": "vulners"
                }
    
    except Exception as e:
        logger.debug(f"Vulners API request failed for {cve}: {e}")
    
    return None


class RateLimiter:
    """Thread-safe rate limiter using token bucket algorithm."""
    
    def __init__(self, max_workers: int, delay: float):
        self.max_workers = max_workers
        self.delay = delay
        self.tokens = max_workers
        self.last_update = time.time()
        self.lock = threading.Lock()
    
    def wait(self):
        """Wait if necessary to respect rate limits."""
        with self.lock:
            now = time.time()
            # Add tokens based on elapsed time
            elapsed = now - self.last_update
            self.tokens = min(self.max_workers, self.tokens + elapsed / self.delay)
            self.last_update = now
            
            if self.tokens >= 1:
                self.tokens -= 1
                return
            
            # Need to wait
            wait_time = self.delay - (elapsed % self.delay)
            time.sleep(wait_time)
            self.tokens = max(0, self.tokens - 1) 